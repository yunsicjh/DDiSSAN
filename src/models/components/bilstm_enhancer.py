import torch
import torch.nn as nn


class BiLSTMEnhancer(nn.Module):
    """
    BiLSTMç‰¹å¾å¢å¼ºæ¨¡å—
    ä¸“é—¨ç”¨äºå¯¹è¯çº§ç‰¹å¾è¿›è¡Œå¢å¼ºå¤„ç†

    åœ¨ä¿®æ­£åçš„SSANæ¶æ„ä¸­ï¼ŒBiLSTMç›´æ¥åœ¨è¯çº§ç‰¹å¾c_sä¸Šæ“ä½œï¼Œ
    äº§ç”Ÿå¢å¼ºçš„è¯çº§ç‰¹å¾c_s_biï¼Œç”¨äºåç»­çš„æ³¨æ„åŠ›è®¡ç®—å’ŒGCNå¤„ç†ã€‚
    """

    def __init__(
        self,
        input_dim: int = 768,
        hidden_dim: int = 384,
        num_layers: int = 1,
        dropout: float = 0.1,
        bidirectional: bool = True,
    ):
        super().__init__()

        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.bidirectional = bidirectional

        # BiLSTMå±‚
        self.bilstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=bidirectional,
            batch_first=True,
        )

        # è¾“å‡ºç»´åº¦ï¼šæŒ‰ç…§prompt.txtè¦æ±‚ï¼ŒBiLSTMéœ€è¦æŠŠç»´åº¦ä»768é™åˆ°128
        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim

        # æœ€ç»ˆè¾“å‡ºç»´åº¦åº”è¯¥æ˜¯128ï¼ˆåŒå‘LSTMçš„hidden_dim * 2 = 128 * 2 = 256ï¼Œéœ€è¦æŠ•å½±åˆ°128ï¼‰
        self.final_output_dim = hidden_dim  # 128ç»´

        # æŠ•å½±å±‚ï¼šå°†åŒå‘LSTMçš„256ç»´è¾“å‡ºæŠ•å½±åˆ°128ç»´
        self.output_projection = nn.Sequential(
            nn.Linear(lstm_output_dim, self.final_output_dim),
            nn.LayerNorm(self.final_output_dim),
            nn.Dropout(dropout),
        )

    def enhance_word_features(
        self,
        word_features: torch.Tensor,
        word_mask: torch.Tensor = None,
    ) -> torch.Tensor:
        """
        å¯¹è¯çº§ç‰¹å¾è¿›è¡ŒBiLSTMå¢å¼º - ä¿®æ­£åæ¶æ„çš„æ ¸å¿ƒæ–¹æ³•

        Args:
            word_features: [batch_size, max_words, input_dim] è¯çº§ç‰¹å¾ c_s
            word_mask: [batch_size, max_words] è¯çº§maskï¼ˆå¯é€‰ï¼‰

        Returns:
            enhanced_word_features: [batch_size, max_words, hidden_dim] å¢å¼ºåçš„è¯çº§ç‰¹å¾ c_s_biï¼ˆ128ç»´ï¼‰
        """
        batch_size, max_words, input_dim = word_features.shape

        # è®¡ç®—å®é™…è¯æ•°é‡ï¼ˆå¦‚æœæä¾›äº†maskï¼‰
        if word_mask is not None:
            word_lengths = word_mask.sum(dim=1)  # [batch_size]
            # ç¡®ä¿é•¿åº¦è‡³å°‘ä¸º1ï¼Œé¿å…pack_padded_sequenceå‡ºé”™
            word_lengths = torch.clamp(word_lengths, min=1)
        else:
            word_lengths = None

        # BiLSTMå¤„ç†
        if word_lengths is not None:
            # ä½¿ç”¨pack_padded_sequenceä¼˜åŒ–å¤„ç†å˜é•¿åºåˆ—
            packed_input = nn.utils.rnn.pack_padded_sequence(
                word_features,
                word_lengths.cpu(),
                batch_first=True,
                enforce_sorted=False,
            )
            packed_output, (hidden, cell) = self.bilstm(packed_input)
            lstm_output, _ = nn.utils.rnn.pad_packed_sequence(
                packed_output, batch_first=True, total_length=max_words
            )
        else:
            # ç›´æ¥å¤„ç†ï¼ˆå½“æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒæ—¶ï¼‰
            lstm_output, (hidden, cell) = self.bilstm(word_features)

        # æŠ•å½±åˆ°åŸå§‹ç»´åº¦
        projected_output = self.output_projection(lstm_output)

        # æŒ‰ç…§prompt.txtè¦æ±‚ï¼Œç›´æ¥è¿”å›é™ç»´åçš„ç‰¹å¾ï¼ˆ768->128ç»´ï¼‰
        # ä¸ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œå› ä¸ºç»´åº¦ä¸åŒ¹é…
        return projected_output


def test_bilstm_enhancer():
    """æµ‹è¯•BiLSTMå¢å¼ºæ¨¡å— - ä¸“æ³¨äºè¯çº§ç‰¹å¾å¤„ç†"""
    print("ğŸ§ª æµ‹è¯•BiLSTMè¯çº§ç‰¹å¾å¢å¼ºæ¨¡å—")

    # åˆ›å»ºæ¨¡å—
    enhancer = BiLSTMEnhancer(
        input_dim=768,
        hidden_dim=384,
        num_layers=1,
        dropout=0.1,
    )

    # æµ‹è¯•è¯çº§ç‰¹å¾å¢å¼º
    batch_size, max_words, hidden_dim = 4, 10, 768
    word_features = torch.randn(batch_size, max_words, hidden_dim)
    word_mask = torch.ones(batch_size, max_words)
    word_mask[0, 8:] = 0  # ç¬¬ä¸€ä¸ªæ ·æœ¬åªæœ‰8ä¸ªè¯
    word_mask[1, 6:] = 0  # ç¬¬äºŒä¸ªæ ·æœ¬åªæœ‰6ä¸ªè¯

    print(f"è¾“å…¥è¯çº§ç‰¹å¾å½¢çŠ¶: {word_features.shape}")
    print(f"è¯çº§maskå½¢çŠ¶: {word_mask.shape}")

    # è¯çº§ç‰¹å¾å¢å¼º
    enhanced_word_features = enhancer.enhance_word_features(word_features, word_mask)

    print(f"å¢å¼ºåè¯çº§ç‰¹å¾å½¢çŠ¶: {enhanced_word_features.shape}")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in enhancer.parameters()):,}")
    print("âœ… BiLSTMè¯çº§å¢å¼ºæ¨¡å—æµ‹è¯•æˆåŠŸï¼")


if __name__ == "__main__":
    test_bilstm_enhancer()
