#!/bin/bash
# SSANæ”¹è¿›æ¨¡å‹å®éªŒå‘½ä»¤é›†åˆ

# SSANæ¨¡å‹debugæµ‹è¯•
python src/train.py experiment=ssan_restaurants debug=fdr
python src/train.py experiment=ssan_laptops debug=fdr
python src/train.py experiment=ssan_tweets debug=fdr

# æ¨¡å‹åœ¨å„æ•°æ®é›†ä¸Šçš„å®Œæ•´è®­ç»ƒ 
python src/train.py experiment=ssan_restaurants trainer=gpu
python src/train.py experiment=ssan_laptops trainer=gpu
python src/train.py experiment=ssan_tweets trainer=gpu


# ============================================================================
# ğŸ”¬ æ”¹è¿›æ¨¡å‹è¶…å‚æ•°è°ƒä¼˜å®éªŒ
# ============================================================================

# Hyperparameter Sweep for Restaurants Dataset
# batch_size=[8,16,32,64], lr=[1e-3,2e-4,3e-5], seed=[1000,1024]
echo "ğŸ½ï¸ Starting Restaurants dataset hyperparameter sweep..."

# Restaurants - Batch size 8
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1024

# Restaurants - Batch size 16
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1024

# Restaurants - Batch size 32
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1024

# Restaurants - Batch size 64
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_restaurants trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1024

echo "âœ… Restaurants dataset sweep completed!"

# Hyperparameter Sweep for Laptops Dataset
# batch_size=[8,16,32,64], lr=[1e-3,2e-4,3e-5], seed=[1000,1024]
echo "ğŸ’» Starting Laptops dataset hyperparameter sweep..."

# Laptops - Batch size 8
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1024

# Laptops - Batch size 16
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1024

# Laptops - Batch size 32
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1024

# Laptops - Batch size 64
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_laptops trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1024

echo "âœ… Laptops dataset sweep completed!"

# Hyperparameter Sweep for Tweets Dataset
# batch_size=[8,16,32,64], lr=[1e-3,2e-4,3e-5], seed=[1000,1024]
echo "ğŸ¦ Starting Tweets dataset hyperparameter sweep..."

# Tweets - Batch size 8
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=8 model.optimizer.lr=3e-5 seed=1024

# Tweets - Batch size 16
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=16 model.optimizer.lr=3e-5 seed=1024

# Tweets - Batch size 32
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=32 model.optimizer.lr=3e-5 seed=1024

# Tweets - Batch size 64
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=1e-3 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=2e-4 seed=1024
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1000
python src/train.py experiment=ssan_tweets trainer=gpu data.batch_size=64 model.optimizer.lr=3e-5 seed=1024

echo "âœ… Tweets dataset sweep completed!"

# ============================================================================
# ğŸ“Š è¶…å‚æ•°æ‰«ææ€»ç»“
# ============================================================================
echo "ğŸ¯ è¶…å‚æ•°æ‰«ææ€»ç»“ï¼š"
echo "   - æ•°æ®é›†: Restaurants, Laptops, Tweets"
echo "   - Batch Size: [8, 16, 32, 64]"
echo "   - Learning Rate: [1e-3, 2e-4, 3e-5]"
echo "   - Random Seeds: [1000, 1024]"
echo "   - æ€»å®éªŒæ•°é‡: 3 datasets Ã— 4 batch_sizes Ã— 3 lr Ã— 2 seeds = 72 experiments"
echo "ğŸš€ æ‰€æœ‰è¶…å‚æ•°æ‰«æå®éªŒå·²å®Œæˆï¼"

# ============================================================================
# ğŸ® ä¾¿æ·è¿è¡Œå‡½æ•° - å¯ä»¥å•ç‹¬è°ƒç”¨
# ============================================================================

# è¿è¡Œå•ä¸ªæ•°æ®é›†çš„è¶…å‚æ•°æ‰«æ
run_restaurants_sweep() {
    echo "ğŸ½ï¸ è¿è¡Œ Restaurants æ•°æ®é›†è¶…å‚æ•°æ‰«æ..."
    # è¿™é‡Œå¯ä»¥å¤åˆ¶ä¸Šé¢ Restaurants çš„æ‰€æœ‰å‘½ä»¤
}

run_laptops_sweep() {
    echo "ğŸ’» è¿è¡Œ Laptops æ•°æ®é›†è¶…å‚æ•°æ‰«æ..."
    # è¿™é‡Œå¯ä»¥å¤åˆ¶ä¸Šé¢ Laptops çš„æ‰€æœ‰å‘½ä»¤
}

run_tweets_sweep() {
    echo "ğŸ¦ è¿è¡Œ Tweets æ•°æ®é›†è¶…å‚æ•°æ‰«æ..."
    # è¿™é‡Œå¯ä»¥å¤åˆ¶ä¸Šé¢ Tweets çš„æ‰€æœ‰å‘½ä»¤
}

# è¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„è¶…å‚æ•°æ‰«æ
run_all_sweeps() {
    echo "ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„è¶…å‚æ•°æ‰«æ..."
    run_restaurants_sweep
    run_laptops_sweep
    run_tweets_sweep
    echo "âœ… æ‰€æœ‰è¶…å‚æ•°æ‰«æå·²å®Œæˆï¼"
}

# ============================================================================
# ğŸ’¡ ä½¿ç”¨è¯´æ˜
# ============================================================================
# è¦è¿è¡Œè¶…å‚æ•°æ‰«æï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
#
# 1. è¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„æ‰«æï¼ˆ72ä¸ªå®éªŒï¼‰ï¼š
#    bash scripts/run.sh
#
# 2. æˆ–è€…åœ¨è„šæœ¬ä¸­è°ƒç”¨ç‰¹å®šå‡½æ•°ï¼š
#    source scripts/run.sh
#    run_restaurants_sweep  # åªè¿è¡Œ Restaurants æ‰«æ
#    run_laptops_sweep      # åªè¿è¡Œ Laptops æ‰«æ  
#    run_tweets_sweep       # åªè¿è¡Œ Tweets æ‰«æ
#
# 3. æˆ–è€…ç›´æ¥æ‰§è¡Œç‰¹å®šéƒ¨åˆ†çš„å‘½ä»¤è¡Œ
#
# ğŸ“Š è¶…å‚æ•°ç½‘æ ¼æœç´¢è¦†ç›–:
# - Restaurants: 4Ã—3Ã—2 = 24 experiments
# - Laptops: 4Ã—3Ã—2 = 24 experiments  
# - Tweets: 4Ã—3Ã—2 = 24 experiments
# - æ€»è®¡: 72 experiments
#
# âš¡ æ¨èä½¿ç”¨é«˜æ•ˆè„šæœ¬:
#    bash scripts/hyperparameter_sweep.sh    # æ›´é«˜æ•ˆçš„æ‰¹é‡è¿è¡Œ
#    python analyze_hyperparameter_results.py # åˆ†æç»“æœå’Œç”Ÿæˆæœ€ä½³é…ç½®
